{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import cv2\n",
    "\n",
    "dataDir = \"/media/james/Datasets_Drive/semg_for_basic_hand_movement/Database_1/\"\n",
    "# dataFiles=['female_1.mat','female_2.mat','female_3.mat','male_1.mat','male_2.mat']\n",
    "dataFiles=['female_1.mat']\n",
    "\n",
    "data = [] #processed and normalised with pose_idx\n",
    "e = 2.718281828459045\n",
    "\n",
    "def normalize_arr(arr,i):\n",
    "    signal = arr.copy()\n",
    "    signal = e**signal\n",
    "    signal /= np.sum(signal)\n",
    "    signal = np.clip(signal,1e-7,1e+7)\n",
    "    signal = signal.tolist()\n",
    "    signal.append(int(i/2))\n",
    "    signal = np.array(signal)\n",
    "    return signal\n",
    "\n",
    "def get_channel_pair(chn1,chn2,i):\n",
    "    paired_data = []\n",
    "    label = list((np.array(chn1).T)[-1].T.astype(int))\n",
    "\n",
    "    chn1 =  list(np.delete(chn1,0,1))\n",
    "    chn2 =  list(np.delete(chn2,0,1))\n",
    "    # print(np.array(chn1).shape)\n",
    "    print(label)\n",
    "    # print('label[i]: ',label[i])\n",
    "    for chunk1 in chn1:\n",
    "        chunk2 = chn2[i].T\n",
    "        chunk1 = chunk1.T\n",
    "\n",
    "        while(len(chunk1)>0):\n",
    "            row=[chunk1[0],chunk2[0],label[5]]\n",
    "            paired_data.append(row)\n",
    "\n",
    "            chunk1 = list(chunk1)\n",
    "            chunk2 = list(chunk2)\n",
    "            chunk1.pop(0)\n",
    "            chunk2.pop(0)\n",
    "\n",
    "    return paired_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in dataFiles:\n",
    "    data_path = dataDir+file\n",
    "    print(data_path)\n",
    "    mat = scipy.io.loadmat(data_path)\n",
    "    mat.pop(\"__header__\")\n",
    "    mat.pop(\"__version__\")\n",
    "    mat.pop(\"__globals__\")\n",
    "    i=0\n",
    "    for channel in mat: \n",
    "        if(i%2==0):\n",
    "            channel2 =  channel[:-1]\n",
    "            channel2 += '2'\n",
    "            sigs1 = mat[channel] \n",
    "            sigs2 = mat[channel2]\n",
    "            sigs1_norm = []\n",
    "            sigs2_norm = []\n",
    "\n",
    "            for signal in sigs1:\n",
    "                signal = normalize_arr(signal,i)\n",
    "                sigs1_norm.append(signal)\n",
    "            for signal in sigs2:\n",
    "                signal = normalize_arr(signal,i)\n",
    "                sigs2_norm.append(signal)\n",
    "\n",
    "            if i==0:\n",
    "                data = get_channel_pair(sigs1_norm,sigs2_norm,i)\n",
    "                # print(data)\n",
    "            else:\n",
    "                None\n",
    "                data_lc = get_channel_pair(sigs1_norm,sigs2_norm,i)\n",
    "                data += data_lc\n",
    "                # data = data_lc\n",
    "        i+=1\n",
    "import pandas as pd\n",
    "import math  \n",
    "def reshape_data(n,df_data):\n",
    "    # get n channel 1 and n channel 2 into 1 sample\n",
    "    chn1 = df_data['channel1'].to_numpy()\n",
    "    chn2 = df_data['channel2'].to_numpy()\n",
    "    label = df_data['label'].to_numpy()\n",
    "    i = 0\n",
    "    newShape_data = []\n",
    "    time = 0\n",
    "    while i < chn1.size:\n",
    "        #currently  the size is 540000, tack batch 20 signals, the loop will rn 27000 times\n",
    "        reshape_data = np.concatenate((chn1[i:i+n], chn2[i:i+n]))\n",
    "        tmp = reshape_data.tolist()\n",
    "        tmp.append(int(label[i]))\n",
    "        tmp = np.array(tmp)\n",
    "\n",
    "        if(len(reshape_data)==n*2):\n",
    "            newShape_data.append(tmp)\n",
    "        i += n\n",
    "        time += 1\n",
    "\n",
    "    newShape_data = np.array(newShape_data)\n",
    "    return newShape_data\n",
    "\n",
    "def split_X(arr):\n",
    "    arr = arr.T\n",
    "    arr = arr[0:-1]\n",
    "    arr = arr.T\n",
    "    return arr\n",
    "def split_y(arr):\n",
    "    arr = arr.T\n",
    "    arr = arr[-1]\n",
    "    arr = arr.T.astype(np.uint8)\n",
    "    return arr\n",
    "def reshape_arr(arr):\n",
    "    new_shape = []\n",
    "    for row in arr:\n",
    "        n_len =int(math.sqrt(len(row)))\n",
    "        row = row.reshape(n_len,n_len)\n",
    "        new_shape.append(row)\n",
    "    return np.array(new_shape)\n",
    "def reshape_arr_img_transfer(arr,n):\n",
    "    new_shape = []\n",
    "    for row in arr:\n",
    "        n_len = len(row)\n",
    "        row =np.pad(row,(0,n-n_len),'constant')\n",
    "        row = row.reshape(n,n)\n",
    "        new_shape.append(row)\n",
    "    return np.array(new_shape)\n",
    "\n",
    "# print(df)\n",
    "dataset = data.copy()\n",
    "df = pd.DataFrame(dataset, columns = ['channel1','channel2','label'])\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "dataset_t_v = df[mask] #test & val\n",
    "dataset_test = df[~mask]\n",
    "\n",
    "val_test_mask = np.random.rand(len(dataset_t_v)) < 0.5\n",
    "dataset_train = dataset_t_v[val_test_mask]\n",
    "dataset_val = dataset_t_v[~val_test_mask]\n",
    "# n=392\n",
    "\n",
    "n=1458\n",
    "dataset_train_ar = reshape_data(n,dataset_train)\n",
    "dataset_test_ar = reshape_data(n,dataset_test)\n",
    "dataset_val_ar = reshape_data(n,dataset_val)\n",
    "print(dataset_train_ar[-20:][-1])\n",
    "\n",
    "np.random.shuffle(dataset_train_ar)\n",
    "np.random.shuffle(dataset_test_ar)\n",
    "np.random.shuffle(dataset_val_ar)\n",
    "\n",
    "print(dataset_train_ar[-20:][-1])\n",
    "\n",
    "X = split_X(dataset_train_ar)\n",
    "y = split_y(dataset_train_ar)\n",
    "\n",
    "\n",
    "X_val = split_X(dataset_train_ar)\n",
    "y_val = split_y(dataset_train_ar)\n",
    "\n",
    "X_test = split_X(dataset_test_ar)\n",
    "y_test = split_y(dataset_test_ar)\n",
    "\n",
    "\n",
    "# OPTIONAL TURN X TO NxN\n",
    "X = reshape_arr(X)\n",
    "X_val = reshape_arr(X_val)\n",
    "X_test = reshape_arr(X_test)\n",
    "\n",
    "# OPTIONAL TURN X TO NxN | N>= 150 transfer learning\n",
    "tuple_size = 150\n",
    "X_tl = reshape_arr_img_transfer(X,tuple_size)\n",
    "X_val_tl = reshape_arr_img_transfer(X_val,tuple_size)\n",
    "X_test_tl = reshape_arr_img_transfer(X_test,tuple_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_test_ar[0][-1])\n",
    "column_name =np.array(list(range(n*2+1)))\n",
    "column_name=column_name+1\n",
    "column_name=column_name.astype('str')\n",
    "column_name\n",
    "df = pd.DataFrame(dataset_test_ar,columns=column_name)\n",
    "df.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(r'/home/james/Documents/hand_project/newdata\\Fnewly_recorded.json',orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
